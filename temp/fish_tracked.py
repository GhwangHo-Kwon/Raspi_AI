import json, cv2, torch, time
from ultralytics import YOLO
from picamera2 import Picamera2

def convert_tensor(obj):
        if isinstance(obj, (float, int)):
            return obj
        elif isinstance(obj, list):
            return [convert_tensor(i) for i in obj]
        elif isinstance(obj, dict):
            return {key: convert_tensor(value) for key, value in obj.items()}
        elif isinstance(obj, torch.Tensor):
            return obj.item()  # Tensorì—ì„œ ê°’ì„ ì¶”ì¶œ
        return obj

model = YOLO('./best.pt')  # í•™ìŠµëœ ë¬¼ê³ ê¸° íƒì§€ ëª¨ë¸

picam2 = Picamera2()

# ì¹´ë©”ë¼ ì´ˆê¸°í™” (í•´ìƒë„/FPSëŠ” í™˜ê²½ì— ë§ê²Œ)
camera_config = picam2.create_video_configuration(
    main={"size": (1280, 720), "format": "RGB888"},  # RGBë¡œ ë°›ìŒ
    controls={"FrameDurationLimits": (33333, 33333)} # â‰ˆ30fps
)
picam2.configure(camera_config)
picam2.start()

# ì²« í”„ë ˆì„ í™•ì¸ ë° í¬ê¸° ì„¤ì •
frame = picam2.capture_array()               # RGB
frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
frame_bgr = cv2.rotate(frame_bgr, cv2.ROTATE_90_COUNTERCLOCKWISE)
height, width = frame_bgr.shape[:2]

last_preview_save = 0.0   # í”„ë¦¬ë·° ì´ë¯¸ì§€ ì£¼ê¸° ì €ì¥ìš©

# ğŸ” ì˜ìƒ ì „ì²´ ì¶”ì  ì‹¤í–‰
try:
    while True:
        # í”„ë ˆì„ íšë“ (RGB â†’ BGR)
        frame = picam2.capture_array()
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

        # íšŒì „ (í•„ìš” ì—†ìœ¼ë©´ ì§€ìš°ì„¸ìš”)
        frame_bgr = cv2.rotate(frame_bgr, cv2.ROTATE_90_COUNTERCLOCKWISE)

        # ğŸ” ê°ì²´ ì¶”ì 
        results = model.track(
            source=frame,
            conf=0.6,
            persist=True,
            verbose=False,
            save_txt=False,
            tracker="./bytetrack.yaml"
            )

        # ê²°ê³¼ ì‹œê°í™”
        annotated_frame = results[0].plot()

        now = time.time()
        if now - last_preview_save > 1.0:
            cv2.imwrite("./tracked_preview.jpg", annotated_frame)
            last_preview_save = now

        # ì¶”ì ëœ ê°ì²´ ì •ë³´ ìˆ˜ì§‘
        frame_data = []
        for result in results[0].boxes:
            # ê° ê°ì²´ì˜ ID, bbox, confidence ê°’ì„ ì¶”ì¶œ
            obj_id = result.id if result.id is not None else -1  # ê°ì²´ IDê°€ Noneì´ë©´ -1ë¡œ ì²˜ë¦¬
            bbox = result.xywh[0].cpu().numpy().tolist()  # ë°”ìš´ë”© ë°•ìŠ¤ (x, y, w, h)
            conf = result.conf[0].cpu().item()  # ì‹ ë¢°ë„ (Tensorì—ì„œ ê°’ì„ ì¶”ì¶œ)

            # ê°ì²´ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            frame_data.append({
                'id': obj_id,
                'bbox': bbox,
                'confidence': conf
            })

        json_obj = json.dumps([convert_tensor(frame) for frame in frame_data], indent=4)
        print(json_obj)


except KeyboardInterrupt:
    pass

picam2.stop()
cv2.destroyAllWindows()
