import json, cv2, torch, time
from ultralytics import YOLO
from picamera2 import Picamera2

def convert_tensor(obj):
        if isinstance(obj, (float, int)):
            return obj
        elif isinstance(obj, list):
            return [convert_tensor(i) for i in obj]
        elif isinstance(obj, dict):
            return {key: convert_tensor(value) for key, value in obj.items()}
        elif isinstance(obj, torch.Tensor):
            return obj.item()  # Tensorì—ì„œ ê°’ì„ ì¶”ì¶œ
        return obj

model = YOLO('./best.pt')  # í•™ìŠµëœ ë¬¼ê³ ê¸° íƒì§€ ëª¨ë¸

picam2 = Picamera2()

# ì¹´ë©”ë¼ ì´ˆê¸°í™” (í•´ìƒë„/FPSëŠ” í™˜ê²½ì— ë§ê²Œ)
camera_config = picam2.create_video_configuration(
    main={"size": (1280, 720), "format": "RGB888"},  # RGBë¡œ ë°›ìŒ
    controls={"FrameDurationLimits": (33333, 33333)} # â‰ˆ30fps
)
picam2.configure(camera_config)
picam2.start()


# ë¹„ë””ì˜¤ ì½ê¸°
# cap = cv2.VideoCapture(0, cv2.CAP_V4L2)
# fps = cap.get(cv2.CAP_PROP_FPS)

# ì²« í”„ë ˆì„ í™•ì¸ ë° í¬ê¸° ì„¤ì •
frame = picam2.capture_array()               # RGB
frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
frame_bgr = cv2.rotate(frame_bgr, cv2.ROTATE_90_COUNTERCLOCKWISE)
height, width = frame_bgr.shape[:2]

# ë¹„ë””ì˜¤ ì €ì¥ (ì‹¤ì‹œê°„ì€ FPSë¥¼ ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •)
fps = 30.0
# out = cv2.VideoWriter(
#     'tracked_live_camera.mp4',
#     cv2.VideoWriter_fourcc(*'mp4v'),
#     fps, (width, height)
# )

# ì¶”ì ëœ ê°ì²´ ì •ë³´ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
# tracked_objects = []
last_preview_save = 0.0   # í”„ë¦¬ë·° ì´ë¯¸ì§€ ì£¼ê¸° ì €ì¥ìš©

# ğŸ” ì˜ìƒ ì „ì²´ ì¶”ì  ì‹¤í–‰
try:
    while True:
        # í”„ë ˆì„ íšë“ (RGB â†’ BGR)
        frame = picam2.capture_array()
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

        # íšŒì „ (í•„ìš” ì—†ìœ¼ë©´ ì§€ìš°ì„¸ìš”)
        frame_bgr = cv2.rotate(frame_bgr, cv2.ROTATE_90_COUNTERCLOCKWISE)

        # ğŸ” ê°ì²´ ì¶”ì 
        results = model.track(
            source=frame,
            conf=0.6,
            persist=True,
            verbose=False,
            save_txt=False,
            tracker="./bytetrack.yaml"
            )

        # ê²°ê³¼ ì‹œê°í™”
        annotated_frame = results[0].plot()
        # out.write(annotated_frame)

        now = time.time()
        if now - last_preview_save > 1.0:
            cv2.imwrite("./tracked_preview.jpg", annotated_frame)
            last_preview_save = now

        # ì¶”ì ëœ ê°ì²´ ì •ë³´ ìˆ˜ì§‘
        frame_data = []
        for result in results[0].boxes:
            # ê° ê°ì²´ì˜ ID, bbox, confidence ê°’ì„ ì¶”ì¶œ
            obj_id = result.id if result.id is not None else -1  # ê°ì²´ IDê°€ Noneì´ë©´ -1ë¡œ ì²˜ë¦¬
            bbox = result.xywh[0].cpu().numpy().tolist()  # ë°”ìš´ë”© ë°•ìŠ¤ (x, y, w, h)
            conf = result.conf[0].cpu().item()  # ì‹ ë¢°ë„ (Tensorì—ì„œ ê°’ì„ ì¶”ì¶œ)

            # ê°ì²´ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            frame_data.append({
                'id': obj_id,
                'bbox': bbox,
                'confidence': conf
            })

        json_obj = json.dumps([convert_tensor(frame) for frame in frame_data], indent=4)
        print(json_obj)

        # ì´ í”„ë ˆì„ì˜ ê°ì²´ ì •ë³´ ì €ì¥
        # tracked_objects.append(frame_data)


except KeyboardInterrupt:
    pass


picam2.stop()

# ì¶”ì ëœ ê°ì²´ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
# Tensor ê°’ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜ í›„ ì €ì¥
# with open('./tracked_sample_robot_fish.json', 'w') as json_file:
    # tracked_objectsì˜ ëª¨ë“  Tensor ê°’ì„ ìˆ«ì ê°’ìœ¼ë¡œ ë³€í™˜
    # (ì˜ˆ: bbox, confidence ë“±)
    # json.dump([convert_tensor(frame) for frame in tracked_objects], json_file, indent=4)

# cap.release()
# out.release()
cv2.destroyAllWindows()
